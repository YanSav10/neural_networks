type: edu
files:
  - name: student.py
    visible: true
    text: |
      import numpy as np
      import pandas as pd
      import os
      import requests
      from matplotlib import pyplot as plt
      
      
      # scroll to the bottom to start coding your solution
      
      
      def one_hot(data: np.ndarray) -> np.ndarray:
          y_train = np.zeros((data.size, data.max() + 1))
          rows = np.arange(data.size)
          y_train[rows, data] = 1
          return y_train
      
      
      def plot(loss_history: list, accuracy_history: list, filename='plot'):
          # function to visualize learning process at stage 4
      
          n_epochs = len(loss_history)
      
          plt.figure(figsize=(20, 10))
          plt.subplot(1, 2, 1)
          plt.plot(loss_history)
      
          plt.xlabel('Epoch number')
          plt.ylabel('Loss')
          plt.xticks(np.arange(0, n_epochs, 4))
          plt.title('Loss on train dataframe from epoch')
          plt.grid()
      
          plt.subplot(1, 2, 2)
          plt.plot(accuracy_history)
      
          plt.xlabel('Epoch number')
          plt.ylabel('Accuracy')
          plt.xticks(np.arange(0, n_epochs, 4))
          plt.title('Accuracy on test dataframe from epoch')
          plt.grid()
      
          plt.savefig(f'{filename}.png')
      
      
      def scale(X_train, X_test):
          # Rescale the data since neural networks don't like big numbers
          X_max = np.max(X_train)
          X_train = X_train / X_max
          X_test = X_test / X_max
          return X_train, X_test
      
      
      def xavier(n_in, n_out):
          # Xavier initialization
          low = -np.sqrt(6 / (n_in + n_out))
          high = np.sqrt(6 / (n_in + n_out))
          return np.random.uniform(low, high, (n_in, n_out))
      
      
      def sigmoid(x):
          # Calculate the sigmoid function
          return 1 / (1 + np.exp(-x))
      
      
      def sigmoid_prime(x):
          # Calculate the derivative of the sigmoid function
          return sigmoid(x) * (1 - sigmoid(x))
      
      
      def mse(y_pred, y_true):
          # Calculate the mean squared error
          return np.mean((y_pred - y_true) ** 2)
      
      
      def mse_prime(y_pred, y_true):
          # Calculate the derivative of the mean squared error
          return 2 * (y_pred - y_true)
      
      
      class OneLayerNeural:
          def __init__(self, n_features, n_classes):
              # Initiate weights and biases using Xavier initialization
              self.W = xavier(n_features, n_classes)
              self.b = xavier(1, n_classes)
      
          def forward(self, X):
              # Perform a forward step
              return sigmoid(np.dot(X, self.W) + self.b)
      
          def backprop(self, X, y, alpha):
              # Perform a backward step
              # Calculate the error
              error = (mse_prime(self.forward(X), y) * sigmoid_prime(np.dot(X, self.W) + self.b))
      
              # Calculate the gradient
              delta_W = (np.dot(X.T, error)) / X.shape[0]
              delta_b = np.mean(error, axis=0)
      
              # Update weights and biases
              self.W -= alpha * delta_W
              self.b -= alpha * delta_b
      
      
      def train(model, X, y, alpha, batch_size=100):
          # Perform a single epoch of training
          n = X.shape[0]
          for i in range(0, n, batch_size):
              model.backprop(X[i:i + batch_size], y[i:i + batch_size], alpha)
      
      
      def accuracy(model, X, y):
          # Calculate the accuracy of the model
          y_pred = np.argmax(model.forward(X), axis=1)
          y_true = np.argmax(y, axis=1)
          return np.mean(y_pred == y_true)
      
      
      if __name__ == '__main__':
      
          if not os.path.exists('../Data'):
              os.mkdir('../Data')
      
          # Download data if it is unavailable.
          if ('fashion-mnist_train.csv' not in os.listdir('../Data') and
                  'fashion-mnist_test.csv' not in os.listdir('../Data')):
              print('Train dataset loading.')
              url = "https://www.dropbox.com/s/5vg67ndkth17mvc/fashion-mnist_train.csv?dl=1"
              r = requests.get(url, allow_redirects=True)
              open('../Data/fashion-mnist_train.csv', 'wb').write(r.content)
              print('Loaded.')
      
              print('Test dataset loading.')
              url = "https://www.dropbox.com/s/9bj5a14unl5os6a/fashion-mnist_test.csv?dl=1"
              r = requests.get(url, allow_redirects=True)
              open('../Data/fashion-mnist_test.csv', 'wb').write(r.content)
              print('Loaded.')
      
          # Read train, test data.
          raw_train = pd.read_csv('../Data/fashion-mnist_train.csv')
          raw_test = pd.read_csv('../Data/fashion-mnist_test.csv')
      
          X_train = raw_train[raw_train.columns[1:]].values
          X_test = raw_test[raw_test.columns[1:]].values
      
          y_train = one_hot(raw_train['label'].values)
          y_test = one_hot(raw_test['label'].values)
      
          # First step: Rescale the data
          X_train, X_test = scale(X_train, X_test)
      
          # Create a class instance and train it
          model = OneLayerNeural(X_train.shape[1], 10)
      
          # Test the accuracy
          r1 = accuracy(model, X_test, y_test).flatten().tolist()
      
          # Train the model (20 epochs)
          r2 = []
          for _ in range(20):
              train(model, X_train, y_train, 0.5)
              r2.append(accuracy(model, X_test, y_test))
      
          # Print the result of the model
          print(r1, r2)
      
          # Save the plot
          # plot(r1, r2, filename="plot")
    learner_created: false
  - name: test/__init__.py
    visible: false
    learner_created: false
  - name: test/tests.py
    visible: false
    text: |
      import numpy as np
      from hstest import StageTest, TestCase, CheckResult
      from hstest.stage_test import List
      from utils.utils import get_list, full_check, custom_uniform
      
      np.random.uniform = custom_uniform
      
      # The source data I will test on
      
      true_forward_res = [0.08145814974665896, 0.7078373861901438, 0.7880474359319048, 0.5460663760416861,
                          0.4142727590233215, 0.3900817619848179, 0.30867710854793123, 0.8821701624025712,
                          0.5251529930398801, 0.6860112311436223, 0.10830624423659274, 0.7042764793747258,
                          0.7896127455170074, 0.5666891692622699, 0.42785055300952424, 0.3886295210179232,
                          0.31683637641989687, 0.8657427046740684, 0.5576544572719793, 0.7183489046929683]
      
      
      class Tests5(StageTest):
      
          def generate(self) -> List[TestCase]:
              return [TestCase(time_limit=1000000)]
      
          def check(self, reply: str, attach):
              reply = reply.strip().lower()
      
              if len(reply) == 0:
                  return CheckResult.wrong("No output was printed")
      
              if reply.count('[') != 1 or reply.count(']') != 1:
                  return CheckResult.wrong('No expected lists were found in output')
      
              try:
                  forward_res, _ = get_list(reply)
              except Exception:
                  return CheckResult.wrong('Seems that MSE output is in wrong format')
      
              check_result = full_check(forward_res, true_forward_res, 'feedforward')
              if check_result:
                  return check_result
      
              return CheckResult.correct()
      
      
      if __name__ == '__main__':
          Tests5().run_tests()
    learner_created: false
  - name: tests.py
    visible: false
    text: |-
      from test.tests import Tests5
      
      if __name__ == '__main__':    Tests5().run_tests()
    learner_created: false
feedback_link: https://hyperskill.org/projects/250/stages/1258/implement#comment
status: Solved
record: 4
